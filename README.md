# Foundation Model Challenge for Ultrasound Image Analysis (FMC_UIA) - Baseline Code

Welcome to the Foundation Model Challenge for Ultrasound Image Analysis (FMC_UIA)! This repository provides baseline code to help you quickly get started with training, inference, and submission.

## ğŸ“‹ Table of Contents

- [Competition Tasks](#competition-tasks)
- [Quick Start](#quick-start)
- [Code Structure](#code-structure)
- [Training Model](#training-model)
- [Local Inference](#local-inference)
- [Docker Build and Test](#docker-build-and-test)
- [Important Notes](#important-notes)
- [FAQ](#faq)

---

## ğŸ¯ Competition Tasks

This challenge includes **4 types of medical image analysis tasks** with a total of **26 subtasks**:

| Task Type | Count | Description | Output Format |
|-----------|-------|-------------|---------------|
| **Segmentation** | 13 | Pixel-level classification | Image |
| **Classification** | 9 | Image classification | JSON file |
| **Detection** | 3 | Object localization | JSON file |
| **Regression** | 2 | Keypoint localization | JSON file |

---


## ğŸš€ Quick Start

### 1. Clone the Code

### 2. Prepare Data

Data directory structure:
```
data/
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ csv_files/              # CSV index files
â”‚   â”‚   â”œâ”€â”€ task1.csv
â”‚   â”‚   â”œâ”€â”€ task2.csv
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ Classification/         # Classification task images
â”‚   â”œâ”€â”€ Segmentation/          # Segmentation task images and masks
â”‚   â”‚   â”œâ”€â”€ Two/               # 2-class segmentation
â”‚   â”‚   â”œâ”€â”€ Three/             # 3-class segmentation
â”‚   â”‚   â”œâ”€â”€ Four/              # 4-class segmentation
â”‚   â”‚   â””â”€â”€ Five/              # 5-class segmentation
â”‚   â”œâ”€â”€ Detection/             # Detection task images
â”‚   â””â”€â”€ Regression/            # Regression task images
â”‚
â””â”€â”€ val/                       # Validation set (same structure as above)
    â”œâ”€â”€ csv_files/
    â”œâ”€â”€ Classification/
    â”œâ”€â”€ Segmentation/
    â”œâ”€â”€ Detection/
    â””â”€â”€ Regression/
```

### 3. Train Model

```bash
python train.py
```

Training will automatically:
- Load data
- Train multi-task model
- Save best model as `best_model.pth`

### 4. Local Inference

```bash
python model.py 
```

---

## ğŸ“ Code Structure

```
baseline/
â”œâ”€â”€ train.py                    # Training script
â”œâ”€â”€ model.py                    # â­ Core: Inference model
â”œâ”€â”€ model_factory.py            # Multi-task model factory
â”œâ”€â”€ dataset.py                  # Dataset loader
â”œâ”€â”€ utils.py                    # Utility functions
â”œâ”€â”€ best_model.pth             # Trained model weights
â”œâ”€â”€ docker/                    # â­ Docker submission related
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ model.py              # Docker version of inference code
â”‚   â”œâ”€â”€ model_factory.py
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”œâ”€â”€ build.sh              # Build script
â”‚   â”œâ”€â”€ run_test.sh           # Test script
â”‚   â”œâ”€â”€ README.md             # Docker detailed documentation
â”‚   â””â”€â”€ QUICKSTART.md         # Quick guide
â””â”€â”€ README.md                  # This file
```

---

## ğŸ“ Training Model

### Training Script

```bash
python train.py
```

### Main Parameters (can be modified in train.py)

```python
LEARNING_RATE = 1e-4
BATCH_SIZE = 8
NUM_EPOCHS = 50
DATA_ROOT_PATH = '/path/to/train'
MODEL_SAVE_PATH = 'best_model.pth'
```

### Training Output

- **Model weights**: `best_model.pth`
- **Training logs**: Terminal output

---

## ğŸ”® Local Inference

###  Using model.py

Modify the paths in `model.py`:

```python
if __name__ == '__main__':
    data_root = '/path/to/your/data'  # Change to your data path
    output_dir = 'predictions/'
    batch_size = 8
    
    model = Model()
    model.predict(data_root, output_dir, batch_size=batch_size)
```

Then run:

```bash
python model.py
```

### Expected Output Structure

```
predictions/
â”œâ”€â”€ classification_predictions.json     # Classification results
â”œâ”€â”€ detection_predictions.json          # Detection results
â”œâ”€â”€ regression_predictions.json         # Regression results
â””â”€â”€ Segmentation/                       # Segmentation results
    â”œâ”€â”€ Two/
    â”‚   â””â”€â”€ (Keep original directory structure)
    â”œâ”€â”€ Three/
    â”œâ”€â”€ Four/
    â””â”€â”€ Five/
```
**Segmentation result path**: Must maintain the same relative path as the `mask_path` field in CSV

Example:
```
mask_path in CSV: ../Segmentation/Two/dataset_name/MASKS/mask_001.png

Output path: {output_dir}/Segmentation/Two/dataset_name/MASKS/mask_001.png
```

## ğŸ³ Docker Build and Test

### âš ï¸ Important Reminder

**Docker is the final submission method!** Please make sure to complete the following steps before submission:

### Step 1: Prepare Docker Files

Copy the following files to the `docker/` directory:

```bash
cd docker/
# Required files:
# - model.py (modified inference code)
# - model_factory.py
# - best_model.pth (trained model)
# - requirements.txt
# - Dockerfile
```

### Step 2: Build Docker Image

```bash
cd docker/
./build.sh
```

Or build manually:

```bash
docker build -f Dockerfile -t my-submission:latest .
```

### Step 3: Test on Validation Set â­

**This step is very important!** Before submission, you must test the Docker on the validation set:

```bash
# Method 1: Use test script
./run_test.sh /path/to/validation /path/to/output

# Method 2: Manual run
docker run --gpus all --rm \
  -v /path/to/validation:/input/:ro \
  -v /path/to/output:/output \
  my-submission:latest
```

### Step 4: Validate Output Format

Check the output directory:

```bash
ls -lh /path/to/output/

# Should contain:
# - classification_predictions.json
# - detection_predictions.json
# - regression_predictions.json
# - Segmentation/ (directory)
```

### Step 5: Upload to Codabench for Evaluation

1. Package output files:
   ```bash
   cd /path/to/output
   zip -r predictions.zip .
   ```

2. Log in to Codabench platform
3. Upload `predictions.zip` for validation set evaluation
4. View evaluation results

**If evaluation passes, it means Docker is built correctly!** You can proceed to the next step.

### Step 6: Submit Docker Image

#### Method A: Docker Hub (Recommended)

```bash
docker login
docker tag my-submission:latest YOUR_USERNAME/my-submission:latest
docker push YOUR_USERNAME/my-submission:latest

# Send the image address to the organizing committee:
# YOUR_USERNAME/my-submission:latest
```

#### Method B: Save as File

```bash
docker save -o my-submission.tar my-submission:latest

# Upload my-submission.tar to cloud storage
# Send the link to the organizing committee
```

---

## âš ï¸ Important Notes

### 1. About model.py â­

**`model.py` is the core file!** You can freely modify its internal implementation, but must follow these specifications:

#### Required Interface

```python
class Model:
    def __init__(self):
        """Initialize model"""
        pass
    
    def predict(self, data_root: str, output_dir: str, batch_size: int = 8):
        """
        Perform inference
        
        Args:
            data_root: Input data root directory (/input/ in Docker)
            output_dir: Output directory (/output/ in Docker)
            batch_size: Batch size
        """
        pass
```

#### Output Format Requirements ğŸ”´ Important!

##### 1) Segmentation Task Output

**Format**: Image file

**Path**: Must maintain the same relative path as the `mask_path` field in CSV

Example:
```
mask_path in CSV: ../Segmentation/Two/dataset_name/MASKS/mask_001.png

Output path: {output_dir}/Segmentation/Two/dataset_name/MASKS/mask_001.png
```

**Pixel values**: 
- Background: 0
- Class 1: 1
- Class 2: 2
- ...

##### 2) Classification Task Output

**Format**: JSON file

**Path**: `{output_dir}/classification_predictions.json`

**Content**:
```json
[
  {
    "image_path": "relative/path/image_001.jpg",
    "task_id": "breast_2cls",
    "predicted_class": 1,
    "predicted_probs": [0.15, 0.85]
  },
  ...
]
```

**Description**:
- `predicted_class`: Predicted class label (integer)
- `predicted_probs`: Prediction probabilities for each class (array, length equals number of classes)
  - Used to calculate evaluation metrics that require probabilities like AUC
  - Sum of all probability values should be 1.0

##### 3) Detection Task Output

**Format**: JSON file

**Path**: `{output_dir}/detection_predictions.json`

**Content**:
```json
[
  {
    "image_path": "relative/path/image_001.jpg",
    "task_id": "thyroid_nodule_det",
    "bbox_normalized": [0.1, 0.2, 0.5, 0.6],
    "bbox_pixels": [50, 100, 250, 300]
  },
  ...
]
```

**Description**:
- `bbox_normalized`: [x_min, y_min, x_max, y_max], normalized to [0, 1]
- `bbox_pixels`: [x_min, y_min, x_max, y_max], pixel coordinates

##### 4) Regression Task Output

**Format**: JSON file

**Path**: `{output_dir}/regression_predictions.json`

**Content**:
```json
[
  {
    "image_path": "relative/path/image_001.jpg",
    "task_id": "FUGC",
    "predicted_points_normalized": [0.3, 0.4, 0.6, 0.7],
    "predicted_points_pixels": [150, 200, 300, 350]
  },
  ...
]
```

**Description**:
- `predicted_points_normalized`: [x1, y1, x2, y2, ...] (normalized coordinates)
- `predicted_points_pixels`: [x1, y1, x2, y2, ...] (pixel coordinates)

### 2. Docker Environment Requirements

- **Input mount point**: `/input/` (read-only)
- **Output mount point**: `/output/` (writable)
- **Memory limit**: Recommended not to exceed 16GB



## â“ FAQ

### Q1: How to modify model architecture?

**A**: You can freely modify the model structure in `model_factory.py`, but make sure:
- Input: RGB images
- Output: Format that meets each task's requirements

### Q2: What if I run out of GPU memory during training?

**A**: Reduce the batch size:
```python
# train.py
BATCH_SIZE = 4  # Change from 8 to 4
```

### Q3: Docker build is very slow?

**A**: 
- First build needs to download base image (~6GB), which takes time
- Subsequent builds will use cache and be faster
- Ensure stable network connection

### Q4: How to verify if output format is correct?

**A**: 
1. Run Docker on validation set
2. Upload output to Codabench platform
3. Platform will automatically validate format and return evaluation results
4. If format is incorrect, there will be clear error messages

### Q5: Can I use my own pre-trained model?

**A**: Yes!
- Model weight files are included in the Docker image

### Q6: Must the inference output path be strictly followed?

**A**: **Yes!** Especially for segmentation task mask paths, they must be completely consistent with the `mask_path` field in CSV (removing the leading `../`). Otherwise, the evaluation platform cannot find the files.

### Q7: How to debug Docker internal issues?

**A**: Enter container for debugging:
```bash
docker run --gpus all --rm \
  -v /path/to/data:/input/:ro \
  -v /path/to/output:/output \
  -it my-submission:latest /bin/bash

# Run manually inside container
python model.py
```


## ğŸ“„ License

This baseline code is for competition use only.

---

## ğŸ‰ Good Luck with the Competition!

Remember the key steps:
1. âœ… Train model
2. âœ… Test inference locally
3. âœ… Build Docker
4. âœ… **Test Docker on validation set**
5. âœ… **Upload predictions to Codabench for validation**
6. âœ… Submit Docker image

**Passing the Codabench evaluation on the validation set ensures your final submission is correct!**

Good luck! ğŸš€

